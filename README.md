# Clustering Hi√©rarchique de Confessions Reddit

Ce projet impl√©mente une analyse de clustering hi√©rarchique sur des confessions Reddit en utilisant des techniques de traitement du langage naturel et d'apprentissage automatique non supervis√©.

## üìã Description

L'objectif de ce projet est d'analyser et de regrouper automatiquement des confessions Reddit en clusters th√©matiques coh√©rents. Le syst√®me utilise la vectorisation TF-IDF et le clustering hi√©rarchique pour identifier des groupes de confessions partageant des caract√©ristiques similaires.

## ‚ú® Fonctionnalit√©s

- **Pr√©processing avanc√©** : Nettoyage et normalisation des textes avec suppression des mots vides
- **Vectorisation TF-IDF** : Transformation des textes en repr√©sentations num√©riques
- **Clustering hi√©rarchique** : Regroupement automatique avec diff√©rentes m√©thodes de liaison
- **Visualisations interactives** : 
  - Dendrogrammes pour visualiser la hi√©rarchie des clusters
  - Projection t-SNE pour la visualisation en 2D
  - Comparaison des m√©thodes de liaison
- **Analyse des clusters** : Extraction des mots-cl√©s caract√©ristiques de chaque groupe
- **Rapport d√©taill√©** : G√©n√©ration automatique d'un rapport d'analyse

## üöÄ R√©sultats

Le syst√®me identifie automatiquement plusieurs types de confessions :

### Cluster 0 - Probl√®mes pratiques et financiers
- **Mots-cl√©s** : order, make, makes, happened, work
- **Th√©matiques** : Difficult√©s financi√®res, probl√®mes de logement, co√ªt de la vie

### Cluster 1 - Probl√®mes √©motionnels et relationnels  
- **Mots-cl√©s** : feel, like, know, dont, really, want, hate
- **Th√©matiques** : Relations amoureuses, estime de soi, probl√®mes familiaux, sant√© mentale

### Cluster 2 - Relations √† long terme
- **Mots-cl√©s** : relationship, long, time, wont
- **Th√©matiques** : Relations durables, engagement, confiance

### Cluster 3 - Observations quotidiennes
- **Th√©matiques** : Habitudes, comportements du quotidien

### Cluster 4 - Questionnements identitaires
- **Mots-cl√©s** : mean, girl, years, dont
- **Th√©matiques** : Orientation sexuelle, identit√©, relations de genre

## üõ†Ô∏è Installation

### Pr√©requis

- Python 3.8+
- pip ou conda

### Installation des d√©pendances

```bash
pip install pandas numpy matplotlib seaborn scikit-learn datasets scipy
```

ou avec conda :

```bash
conda install pandas numpy matplotlib seaborn scikit-learn scipy
pip install datasets  # datasets n'est pas disponible via conda
```

### D√©pendances compl√®tes

```
pandas>=1.3.0
numpy>=1.21.0
matplotlib>=3.4.0
seaborn>=0.11.0
scikit-learn>=1.0.0
datasets>=2.0.0
scipy>=1.7.0
```

## üìä Utilisation

### Ex√©cution de base

```bash
python algo.py
```

### Param√®tres configurables

Dans le fichier `algo.py`, vous pouvez modifier :

- `sample_size` : Nombre de confessions √† analyser (d√©faut: 50)
- `n_clusters` : Nombre de clusters souhait√© (d√©faut: 5)
- `max_features` : Nombre maximum de caract√©ristiques TF-IDF (d√©faut: 100)

### Exemple d'utilisation personnalis√©e

```python
# Modifier la taille de l'√©chantillon
sample_size = 100

# Changer le nombre de clusters
n_clusters = 7

# Ajuster les param√®tres TF-IDF
vectorizer = TfidfVectorizer(
    max_features=200, 
    min_df=3, 
    stop_words='english',
    ngram_range=(1, 2)  # Inclure les bigrammes
)

## üìà Sorties g√©n√©r√©es

Le script g√©n√®re automatiquement :

1. **dendrogram.png** : Dendrogramme principal montrant la hi√©rarchie des clusters
2. **linkage_methods.png** : Comparaison de 4 m√©thodes de liaison diff√©rentes
3. **optimal_clusters.png** : Analyse du nombre optimal de clusters
4. **tsne_clusters.png** : Visualisation 2D des clusters avec t-SNE
5. **cluster_analysis.txt** : Rapport d√©taill√© avec mots-cl√©s et exemples

## üîß Algorithmes utilis√©s

- **Pr√©processing** : Tokenisation, suppression des mots vides, normalisation
- **Vectorisation** : TF-IDF (Term Frequency-Inverse Document Frequency)
- **Clustering** : Clustering hi√©rarchique agglom√©ratif avec diff√©rentes m√©thodes de liaison
- **Visualisation** : t-SNE (t-Distributed Stochastic Neighbor Embedding)
- **Analyse** : Extraction des termes les plus discriminants par cluster

## üìö Dataset

Le projet utilise le dataset "SocialGrep/one-million-reddit-confessions" disponible sur Hugging Face, contenant plus d'un million de confessions anonymes Reddit.

**Caract√©ristiques du dataset :**
- Source : r/confession et subreddits similaires
- Contenu : Texte des confessions + titres
- Taille : ~1M d'entr√©es
- Langue : Anglais principalement

## ‚öôÔ∏è Configuration avanc√©e

### Optimisation des performances

Pour de gros volumes de donn√©es :

```python
# Utiliser un √©chantillon stratifi√©
sample_df = df.sample(n=1000, random_state=42)

# Optimiser TF-IDF
vectorizer = TfidfVectorizer(
    max_features=500,
    min_df=5,
    max_df=0.95,
    stop_words='english'
)

# Utiliser PCA avant clustering pour r√©duire la dimensionnalit√©
from sklearn.decomposition import PCA
pca = PCA(n_components=50)
X_reduced = pca.fit_transform(X_dense)
```

### M√©thodes de liaison disponibles

- **single** : Distance minimale entre clusters
- **complete** : Distance maximale entre clusters  
- **average** : Distance moyenne entre clusters
- **ward** : Minimise la variance intra-cluster (recommand√©e)

## üîó R√©f√©rences

- [Dataset Reddit Confessions](https://huggingface.co/datasets/SocialGrep/one-million-reddit-confessions)
- [Scikit-learn Clustering](https://scikit-learn.org/stable/modules/clustering.html)
- [TF-IDF Vectorization](https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction)
